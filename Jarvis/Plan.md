# Jarvis Project Plan - Holistic Refactoring Strategy

## Project Vision

Jarvis is an intelligent voice assistant that combines a modern macOS SwiftUI interface with a powerful Python backend. The system provides both text-based chat interactions and hands-free voice control through wake word detection and speech synthesis. This plan outlines a comprehensive refactoring strategy to transform the current basic implementation into a sophisticated, production-ready macOS AI chat application.

## Current State Analysis

### âœ… What's Already Implemented

**Backend (Python) - Well Developed:**
- Complete voice assistant with wake word detection ("Jarvis")
- Speech-to-text using Whisper
- Text-to-speech using Cartesia TTS
- LLM interface with Ollama integration (local models)
- System automation capabilities
- Audio processing pipeline with adaptive silence detection
- Rich console interface for debugging
- Flask API server with WebSocket support
- Search functionality with Google integration
- Context management and memory system

**Frontend (SwiftUI) - Basic Implementation:**
- Simple chat interface with markdown support
- Basic message display and input
- Dark theme UI
- AppleScript integration for external commands
- SwiftData for persistence
- Single ContentView architecture

### ðŸ”„ What Needs to Be Built

**Phase 1: Frontend Architecture Overhaul**
- Modular SwiftUI architecture with proper MVVM pattern
- Enhanced chat interface with conversation management
- Voice mode UI with AI sphere visualization
- Settings and configuration interface
- Real-time communication infrastructure

**Phase 2: Backend API Enhancement**
- Enhanced Flask API with conversation management
- Streaming support for real-time responses
- Improved error handling and status codes
- Conversation persistence with proper data models
- Enhanced WebSocket events for real-time communication

**Phase 3: Advanced Features & Integration**
- System integration and automation
- Performance optimizations
- Comprehensive testing suite
- Production-ready deployment

## Detailed Implementation Plan

### Phase 1: Frontend Architecture Overhaul (Weeks 1-3)

#### 1.1 New Frontend Architecture Structure
**Priority: Critical**

**New Architecture:**
```
Jarvis/Jarvis/
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ JarvisApp.swift              # Main app entry point
â”‚   â”œâ”€â”€ AppDelegate.swift            # System integration
â”‚   â””â”€â”€ Info.plist
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ CoreData/
â”‚   â”‚   â”œâ”€â”€ DataController.swift     # CoreData stack
â”‚   â”‚   â”œâ”€â”€ Jarvis.xcdatamodeld      # Data model
â”‚   â”‚   â”œâ”€â”€ Chat+CoreDataClass.swift
â”‚   â”‚   â”œâ”€â”€ Message+CoreDataClass.swift
â”‚   â”‚   â””â”€â”€ Conversation+CoreDataClass.swift
â”‚   â”œâ”€â”€ ChatModels.swift             # Chat-related models
â”‚   â”œâ”€â”€ APIModels.swift              # API request/response models
â”‚   â””â”€â”€ AppState.swift               # Global app state
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ Chat/
â”‚   â”‚   â”œâ”€â”€ ChatView.swift           # Main chat interface
â”‚   â”‚   â”œâ”€â”€ ChatListView.swift       # Sidebar with chat list
â”‚   â”‚   â”œâ”€â”€ MessageBubbleView.swift  # Individual message view
â”‚   â”‚   â”œâ”€â”€ MessageInputView.swift   # Text input component
â”‚   â”‚   â””â”€â”€ CodeBlockView.swift      # Code syntax highlighting
â”‚   â”œâ”€â”€ Voice/
â”‚   â”‚   â”œâ”€â”€ VoiceModeView.swift      # Voice interaction UI
â”‚   â”‚   â”œâ”€â”€ AISphereView.swift       # Animated AI sphere
â”‚   â”‚   â”œâ”€â”€ VoiceActivityView.swift  # Audio visualization
â”‚   â”‚   â””â”€â”€ MicrophoneView.swift     # Microphone controls
â”‚   â”œâ”€â”€ Settings/
â”‚   â”‚   â”œâ”€â”€ SettingsView.swift       # Main settings window
â”‚   â”‚   â”œâ”€â”€ APISettingsView.swift    # API configuration
â”‚   â”‚   â”œâ”€â”€ VoiceSettingsView.swift  # Voice settings
â”‚   â”‚   â””â”€â”€ GeneralSettingsView.swift
â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”œâ”€â”€ SearchBar.swift          # Search functionality
â”‚   â”‚   â”œâ”€â”€ SidebarView.swift        # App sidebar
â”‚   â”‚   â”œâ”€â”€ LoadingIndicator.swift   # Loading states
â”‚   â”‚   â””â”€â”€ ErrorView.swift          # Error handling
â”‚   â””â”€â”€ Onboarding/
â”‚       â””â”€â”€ WelcomeView.swift        # First-time setup
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ APIClient/
â”‚   â”‚   â”œâ”€â”€ APIClientProtocol.swift  # API client interface
â”‚   â”‚   â”œâ”€â”€ JarvisAPIClient.swift    # Main API client
â”‚   â”‚   â”œâ”€â”€ WebSocketClient.swift    # Real-time communication
â”‚   â”‚   â””â”€â”€ StreamingParser.swift    # SSE handling
â”‚   â”œâ”€â”€ AudioManager/
â”‚   â”‚   â”œâ”€â”€ AudioManager.swift       # Audio recording/playback
â”‚   â”‚   â”œâ”€â”€ AudioStreamer.swift      # Real-time audio streaming
â”‚   â”‚   â””â”€â”€ AudioVisualizer.swift    # Audio visualization
â”‚   â”œâ”€â”€ CoreDataService.swift        # Database operations
â”‚   â”œâ”€â”€ SearchService.swift          # Search functionality
â”‚   â””â”€â”€ ExportService.swift          # Chat export
â”œâ”€â”€ ViewModels/
â”‚   â”œâ”€â”€ ChatViewModel.swift          # Chat logic
â”‚   â”œâ”€â”€ VoiceViewModel.swift         # Voice interaction logic
â”‚   â”œâ”€â”€ SettingsViewModel.swift      # Settings management
â”‚   â””â”€â”€ SearchViewModel.swift        # Search logic
â”œâ”€â”€ Utils/
â”‚   â”œâ”€â”€ Extensions/
â”‚   â”‚   â”œâ”€â”€ String+Extensions.swift
â”‚   â”‚   â”œâ”€â”€ View+Extensions.swift
â”‚   â”‚   â””â”€â”€ Color+Extensions.swift
â”‚   â”œâ”€â”€ Constants.swift              # App constants
â”‚   â”œâ”€â”€ KeychainHelper.swift         # Secure storage
â”‚   â”œâ”€â”€ MarkdownParser.swift         # Message formatting
â”‚   â””â”€â”€ PermissionsManager.swift     # System permissions
â””â”€â”€ Resources/
    â”œâ”€â”€ Assets.xcassets
    â”œâ”€â”€ Localizable.strings
    â””â”€â”€ Credits.rtf
```

#### 1.2 Enhanced Chat Interface
**Priority: High**
- **Replace current ContentView** with modular ChatView
- **Implement conversation management** with CoreData
- **Add message threading** and async handling
- **Enhance markdown rendering** with syntax highlighting
- **Add message reactions** and editing capabilities
- **Create conversation history** with search and filtering

#### 1.3 Voice Integration UI
**Priority: High**
- **Create VoiceModeView** with AI sphere animation
- **Implement smooth transitions** between chat and voice modes
- **Add voice activity indicators** (waveform visualization)
- **Create microphone permission** handling
- **Design AI sphere animation** for voice mode

#### 1.4 Settings & Configuration
**Priority: Medium**
- **Create comprehensive settings UI**
- **Add API configuration** management
- **Implement voice settings** (TTS voice, sensitivity)
- **Add theme customization**
- **Create keyboard shortcuts**

#### 1.5 State Management
**Priority: Medium**
- **Create JarvisStateManager** for global state
- **Implement mode switching** (chat â†” voice)
- **Add wake word detection** status
- **Create settings persistence**

### Phase 2: Backend API Enhancement (Weeks 4-5)

#### 2.1 Enhanced Flask API Server
**Priority: Critical**

**Current API Enhancements Needed:**
- **Conversation Management:**
  - Add conversation CRUD operations
  - Implement conversation threading
  - Add conversation metadata (title, tags, etc.)

- **Streaming Support:**
  - Enhance current chat endpoint for streaming responses
  - Add proper SSE (Server-Sent Events) implementation
  - Implement real-time status updates

- **Enhanced Error Handling:**
  - Add proper HTTP status codes
  - Implement retry mechanisms
  - Add detailed error messages

#### 2.2 API Endpoints Enhancement
**Priority: High**

**Enhanced Endpoints:**
```python
# Enhanced Flask API endpoints
POST /api/v1/chat
{
    "message": "Hello Jarvis",
    "conversation_id": "uuid",
    "stream": true  # Enable streaming response
}

GET /api/v1/conversations
# List all conversations with metadata

POST /api/v1/conversations
# Create new conversation

GET /api/v1/conversations/{conversation_id}
# Get conversation with full history

DELETE /api/v1/conversations/{conversation_id}
# Delete conversation

POST /api/v1/voice/start
# Start voice recording session

POST /api/v1/voice/stop
# Stop voice recording and process

GET /api/v1/status
# Returns system status and capabilities

GET /api/v1/models
# List available LLM models
```

#### 2.3 WebSocket Enhancement
**Priority: High**
- **Real-time conversation updates**
- **Voice activity streaming**
- **System status notifications**
- **Wake word detection events**

### Phase 3: Advanced Features & Integration (Week 6)

#### 3.1 System Integration
**Priority: Medium**
- **Enhance AppleScript integration** for system automation
- **Add file operations** interface
- **Implement calendar integration**
- **Create system status monitoring**

#### 3.2 Performance & Polish
**Priority: Medium**
- **Optimize API response times**
- **Implement proper caching**
- **Add comprehensive error handling**
- **Create unit tests**
- **Add performance monitoring**

#### 3.3 Audio Integration
**Priority: High**
- **Implement audio recording** in SwiftUI using AVFoundation
- **Create audio streaming** to Python backend
- **Add real-time audio level** monitoring
- **Implement audio playback** for TTS responses

## Technical Architecture

### Backend Architecture (Enhanced)
```
Backend/
â”œâ”€â”€ api_server.py          # Enhanced Flask API server
â”œâ”€â”€ jarvis.py             # Voice assistant core
â”œâ”€â”€ llm_interface.py      # LLM integration
â”œâ”€â”€ automation.py         # System automation
â”œâ”€â”€ cartesia_tts.py       # Text-to-speech
â”œâ”€â”€ wake_word/            # Wake word detection
â”œâ”€â”€ search/               # Search functionality
â”œâ”€â”€ context.py            # Context management
â””â”€â”€ storage/              # Data persistence
```

### Frontend Architecture (New)
```
Jarvis/Jarvis/
â”œâ”€â”€ App/                  # App entry point and configuration
â”œâ”€â”€ Models/               # Data models and CoreData
â”œâ”€â”€ Views/                # SwiftUI views organized by feature
â”œâ”€â”€ Services/             # Business logic and external services
â”œâ”€â”€ ViewModels/           # MVVM view models
â”œâ”€â”€ Utils/                # Utilities and extensions
â””â”€â”€ Resources/            # Assets and localization
```

## Implementation Details

### SwiftUI Data Flow
```swift
// Main data flow
JarvisApp
â”œâ”€â”€ ContentView (main container)
â”‚   â”œâ”€â”€ ChatView (text chat interface)
â”‚   â”œâ”€â”€ VoiceModeView (voice interaction)
â”‚   â””â”€â”€ SettingsView (configuration)
â”œâ”€â”€ ChatViewModel (chat logic)
â”œâ”€â”€ VoiceViewModel (voice interaction logic)
â””â”€â”€ JarvisStateManager (global state)

// API communication
JarvisAPIClient
â”œâ”€â”€ HTTP requests for chat
â”œâ”€â”€ WebSocket for real-time updates
â””â”€â”€ Audio streaming for voice
```

### CoreData Models
```swift
// CoreData entities
Chat
â”œâ”€â”€ id: UUID
â”œâ”€â”€ title: String
â”œâ”€â”€ createdAt: Date
â”œâ”€â”€ updatedAt: Date
â”œâ”€â”€ messages: [Message]
â””â”€â”€ isActive: Bool

Message
â”œâ”€â”€ id: UUID
â”œâ”€â”€ content: String
â”œâ”€â”€ isUser: Bool
â”œâ”€â”€ timestamp: Date
â”œâ”€â”€ chat: Chat
â””â”€â”€ metadata: Data

Conversation
â”œâ”€â”€ id: UUID
â”œâ”€â”€ title: String
â”œâ”€â”€ createdAt: Date
â”œâ”€â”€ lastMessage: String
â””â”€â”€ messageCount: Int32
```

## Development Phases

### Phase 1: Frontend Foundation (Weeks 1-3)
**Goal**: Establish new modular frontend architecture

**Deliverables**:
- [ ] New modular SwiftUI architecture
- [ ] Enhanced chat interface with CoreData
- [ ] Voice mode UI with animations
- [ ] Settings and configuration interface
- [ ] State management system

**Success Criteria**:
- New architecture is in place and functional
- Chat interface works with mock data
- Voice mode UI is visually appealing
- Settings are persistent and user-friendly

### Phase 2: Backend Enhancement (Weeks 4-5)
**Goal**: Enhance backend API to support new frontend features

**Deliverables**:
- [ ] Enhanced Flask API with conversation management
- [ ] Streaming support for real-time responses
- [ ] Improved error handling and status codes
- [ ] Enhanced WebSocket events
- [ ] API documentation

**Success Criteria**:
- API supports all new frontend features
- Streaming responses work correctly
- Error handling is comprehensive
- WebSocket communication is stable

### Phase 3: Integration & Polish (Week 6)
**Goal**: Complete integration and add advanced features

**Deliverables**:
- [ ] Full frontend-backend integration
- [ ] Audio recording and streaming
- [ ] System automation integration
- [ ] Performance optimizations
- [ ] Comprehensive testing

**Success Criteria**:
- Text and voice chat work seamlessly
- Audio processing is smooth and responsive
- System integration functions properly
- App performance is excellent

## Technical Considerations

### Performance
- Use background threads for API calls
- Implement audio buffering for smooth streaming
- Cache frequently used data
- Optimize UI rendering for real-time updates
- Use CoreData efficiently for large datasets

### Security
- Implement API authentication
- Secure audio data transmission
- Handle sensitive user data properly
- Add input validation and sanitization
- Use Keychain for secure storage

### User Experience
- Provide clear loading and error states
- Implement smooth animations and transitions
- Add keyboard shortcuts for power users
- Ensure accessibility compliance
- Create intuitive mode switching

### Testing
- Unit tests for API endpoints
- UI tests for SwiftUI components
- Integration tests for end-to-end workflows
- Performance testing for audio processing
- CoreData migration testing

## Dependencies & Requirements

### Backend Dependencies
- Flask (API server)
- WebSocket support (python-socketio)
- Audio processing libraries (sounddevice, whisper)
- LLM integration (ollama)
- Search functionality (google-search-python)

### Frontend Dependencies
- AVFoundation (audio handling)
- CoreData (persistence)
- WebSocket client
- Animation frameworks
- SwiftUI (macOS 14.0+)

### System Requirements
- macOS 14.0+
- Microphone permissions
- Network connectivity
- Python 3.8+ (backend)
- Xcode 15.0+

## Risk Assessment

### High Risk
- **Audio synchronization**: Complex audio streaming between SwiftUI and Python
- **Real-time performance**: Ensuring smooth UI updates during voice processing
- **Wake word reliability**: Maintaining accurate detection in various environments
- **CoreData migration**: Ensuring data integrity during architecture changes

### Medium Risk
- **API stability**: Ensuring robust communication between components
- **State management**: Complex state transitions between chat and voice modes
- **Memory usage**: Audio buffering and processing memory requirements
- **UI performance**: Maintaining smooth animations with complex data

### Low Risk
- **UI implementation**: Standard SwiftUI patterns
- **Data persistence**: Well-established CoreData framework
- **Error handling**: Standard error handling patterns
- **Settings management**: Standard macOS patterns

## Success Metrics

### Phase 1 Success Metrics
- [ ] App launch time < 3 seconds
- [ ] Smooth 60fps animations
- [ ] CoreData operations < 100ms
- [ ] UI responsiveness < 16ms

### Phase 2 Success Metrics
- [ ] API response time < 2 seconds
- [ ] 99% uptime for API server
- [ ] WebSocket connection stability > 95%
- [ ] Zero data loss in conversations

### Phase 3 Success Metrics
- [ ] Voice mode activation < 1 second
- [ ] Audio latency < 100ms
- [ ] Wake word accuracy > 95%
- [ ] User satisfaction score > 4.5/5

## Migration Strategy

### Phase 1 Migration
1. **Create new architecture** alongside existing code
2. **Implement CoreData models** and data controller
3. **Build new views** with mock data
4. **Test new architecture** thoroughly

### Phase 2 Migration
1. **Enhance backend API** to support new features
2. **Update API client** to use new endpoints
3. **Integrate real data** with new frontend
4. **Test full integration**

### Phase 3 Migration
1. **Remove old code** and clean up
2. **Optimize performance** and add polish
3. **Add advanced features** and system integration
4. **Comprehensive testing** and bug fixes

## Next Steps

1. **Immediate**: Begin Phase 1 - Create new frontend architecture
2. **Week 1**: Implement CoreData models and basic views
3. **Week 2**: Build chat interface and voice mode UI
4. **Week 3**: Complete settings and state management
5. **Week 4**: Begin Phase 2 - Enhance backend API
6. **Week 5**: Complete API enhancement and integration
7. **Week 6**: Phase 3 - Polish and advanced features

## Conclusion

This comprehensive plan transforms Jarvis from a basic chat interface into a sophisticated macOS AI assistant with voice capabilities, proper data persistence, and a modern, modular architecture. By prioritizing frontend changes before backend alterations, we ensure a solid foundation for the enhanced features.

The new architecture provides:
- **Scalability**: Modular design allows easy feature additions
- **Maintainability**: Clear separation of concerns and proper patterns
- **Performance**: Optimized for real-time audio and UI updates
- **User Experience**: Modern, intuitive interface with smooth animations
- **Reliability**: Comprehensive error handling and testing

This plan delivers a production-ready application that combines the power of Python's AI/ML ecosystem with SwiftUI's modern UI capabilities, creating a unique and powerful voice assistant platform. 